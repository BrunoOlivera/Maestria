{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNJcL_gq9JCM"
   },
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WcWZuNt9JCZ"
   },
   "source": [
    "Es necesario importar las librerias a utilizar, se usará spacy, pandas, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RhnpkFPSBHmR"
   },
   "outputs": [],
   "source": [
    "# Ejecutar este fragmento si se ejecuta en colab\n",
    "!pip install unidecode\n",
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "s-9wnPcN9VZJ"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2a534f3c8ddb>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2a534f3c8ddb>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    carpeta_laboratorios =\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar este fragmento si se ejecuta en colab\n",
    "# Debes autorizar a colab a acceder a tus archivos\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/lab')\n",
    "\n",
    "# En esta variable va la carpeta donde están los laboratorios en drive\n",
    "carpeta_laboratorios = \n",
    "\n",
    "path_laboratorios = '/lab/My Drive/' + carpeta_laboratorios + '/'\n",
    "print('Los archivos en tu carpeta de laboratoros son:')\n",
    "os.listdir(path_laboratorios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "LBWmCS7h9JCi"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "# from spacy import displacy\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yvwHwBGy9JC8"
   },
   "source": [
    "#### Practicar Expresiones Regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wg-ORdl59JDC"
   },
   "source": [
    "Dada una lista de palabras, imprimir los elementos que contengan un determinado string\n",
    "1. en cualquier lugar de la palabra\n",
    "2. teriminen en ese string\n",
    "\n",
    "Puede realizarlo usando la funcion match o la search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Dw-7daBy9JDL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pera\n",
      "espera\n",
      "marinerala\n",
      "eramente\n"
     ]
    }
   ],
   "source": [
    "# ejemplo de busqueda de patron\n",
    "# a) contienen era\n",
    "\n",
    "lista = ['pera', 'espera','camino','marinerala', 'eramente']\n",
    "for elem in lista:\n",
    "    if re.match(r'.*era.*',elem):\n",
    "        print(elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dUxrsDb79JDd"
   },
   "outputs": [],
   "source": [
    "# el search es como el match pero busca la ER en cualquier lugar de la cadena \n",
    "# sin necesidad de poner los símbolos de comienzo o fin poner el .*\n",
    "# a) variante\n",
    "\n",
    "lista = ['pera', 'espera','camino','marinerala','eramente']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "0Mq8m-Ur9JDv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pera\n",
      "espera\n"
     ]
    }
   ],
   "source": [
    "# b) terminan en era y antes puede haber cualquier otro símbolo\n",
    "\n",
    "lista = ['pera', 'espera','camino','marinerala', 'eramente']\n",
    "for elem in lista:\n",
    "    if re.match(r'.*(era)$',elem):\n",
    "        print(elem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWUD5Ukm9JD_"
   },
   "source": [
    "#### Practicar sustituciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFdDp7ts9JEF"
   },
   "source": [
    "Dada la oracion    'Si mañana vengo mañana voy a ver si consigo que mañana sea hoy' \n",
    "\n",
    "Sustituya las ocurrencias de la palabra mañana por la palabra hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "39SqApGD9JEK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Si hoy vengo hoy voy a ver si consigo que hoy sea hoy'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ejemplo de sustitución\n",
    "\n",
    "oracion = 'Si mañana vengo mañana voy a ver si consigo que mañana sea hoy'\n",
    "re.sub('mañana','hoy',oracion)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfQtG_8F9JEe"
   },
   "source": [
    "Elimina palabras seguidas iguales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "oyYmesOI9JEl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'si hooy hoy llueve'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sustituciones con ER, elimina palabras seguidas iguales, dejando solo una\n",
    "oracion = 'si hooy hoy llueve llueve'\n",
    "re.sub(r'(\\w+) \\1',r'\\1',oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "roqWdqzI9JE0"
   },
   "source": [
    "Elimine las líneas en blanco que puedan estar en medio de una oración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "_taZjLQ79JE4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si hoy\n",
      "llueve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'si hoy llueve'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Por ejemplo, sustitúyalas por un \"espacio\"\n",
    "oracion = 'si hoy\\nllueve'\n",
    "print(oracion)\n",
    "re.sub(r'\\n',r' ',oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1a2SirUC9JFH"
   },
   "source": [
    "#### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "km6U6qei9JFN"
   },
   "source": [
    "Hay que cargar los datos para desarrollo a partir del archivo csv provisto (devel.csv). Pandas cuenta con una funcion para cargar csv. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "z_esmiW19JFU"
   },
   "outputs": [],
   "source": [
    "df_devel = pd.read_csv('devel.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVnSP36R9JFj"
   },
   "source": [
    "Es posible ver la composición general de los datos con la función info de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "PW7bkrWY9JFm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1133 entries, 0 to 1132\n",
      "Data columns (total 3 columns):\n",
      "0    1133 non-null int64\n",
      "1    1133 non-null object\n",
      "2    1133 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 26.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_devel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "N-ZQwUvs9JFw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187437263205044224</td>\n",
       "      <td>Estos días trataré de hacer deporte con mis am...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180438913880571904</td>\n",
       "      <td>Un mensaje especial para un luchador como Eric...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771051726694744064</td>\n",
       "      <td>Chicxs nunca idealicéis demasiado a una person...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>810700953620021248</td>\n",
       "      <td>@wkCArlos yo soy igual Jajajaja trató de evita...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>769894353389162497</td>\n",
       "      <td>Y yo mientras comeré palomitas mientras quedái...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>817151700335267841</td>\n",
       "      <td>Lo bueno: el gato regresó. Lo malo: creo que e...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>159520155372765184</td>\n",
       "      <td>Recuerdo a Garzon ,bermejo,la fiscal,el poli d...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>178812716499218432</td>\n",
       "      <td>Llena de tristeza que víctimas del terrorismo ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>145810899008110592</td>\n",
       "      <td>RT @Ciutadans_Cs: A las 13h, no te pierdas a I...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>158684073529843712</td>\n",
       "      <td>Fraga sera velado en su domicilio este lunes y...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1     2\n",
       "0  187437263205044224  Estos días trataré de hacer deporte con mis am...     P\n",
       "1  180438913880571904  Un mensaje especial para un luchador como Eric...     P\n",
       "2  771051726694744064  Chicxs nunca idealicéis demasiado a una person...     N\n",
       "3  810700953620021248  @wkCArlos yo soy igual Jajajaja trató de evita...   NEU\n",
       "4  769894353389162497  Y yo mientras comeré palomitas mientras quedái...     N\n",
       "5  817151700335267841  Lo bueno: el gato regresó. Lo malo: creo que e...   NEU\n",
       "6  159520155372765184  Recuerdo a Garzon ,bermejo,la fiscal,el poli d...     N\n",
       "7  178812716499218432  Llena de tristeza que víctimas del terrorismo ...     N\n",
       "8  145810899008110592  RT @Ciutadans_Cs: A las 13h, no te pierdas a I...  NONE\n",
       "9  158684073529843712  Fraga sera velado en su domicilio este lunes y...  NONE"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pzvPmMzf9JF-"
   },
   "source": [
    "Es posible imprimir el texto completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "nOAR_FXn9JGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estos días trataré de hacer deporte con mis amigos y desconectar.\n",
      "Un mensaje especial para un luchador como Eric Abidal. Toda la fuerza para tu recuperación. Estamos con vos!\n",
      "Chicxs nunca idealicéis demasiado a una persona, que luego os da mg en facebook y rompéis un espejo de la emoción \n",
      "@wkCArlos yo soy igual Jajajaja trató de evitarlo pero no lo logro\n",
      "Y yo mientras comeré palomitas mientras quedáis retratados porque, ay, es lo que pasa cuando usas el activismo como un arma \n",
      "Lo bueno: el gato regresó. Lo malo: creo que es del vecino y no me lo puedo dejar.\n",
      "Recuerdo a Garzon ,bermejo,la fiscal,el poli de la judicial cazando gratis con Correa en el calabozo...\n",
      "Llena de tristeza que víctimas del terrorismo como #Pilar Manjón pretendan boicotear el trabajo de la justicia en el #11M #11Mconlasvíctimas\n",
      "RT @Ciutadans_Cs: A las 13h, no te pierdas a Inés Arrimadas en la tertulia \"La Alternativa de Cope Bcn #CsTeam\n",
      "Fraga sera velado en su domicilio este lunes y el martes sera trasladado a Perbes(Lugo) donde será enterrado. Es la intención de la familia.\n"
     ]
    }
   ],
   "source": [
    "# seleccionamos los primeros 10 tweets\n",
    "\n",
    "for tweet in df_devel[1].values[:10]:\n",
    "    print(tweet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Cdkdsy6k9JGO"
   },
   "outputs": [],
   "source": [
    "# hacer lo mismo con el corpus de entrenamiento train los 20 primeros tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnkh6nwt9JGf"
   },
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fZeBCmg9JGi"
   },
   "source": [
    "Para el procesamiento posterior del texto puede ser útil modificar el texto original para que sea más manejable. En el caso de los tweets puede tener sentido ignorar los Hashtags, Mentions y Urls para que no tenerlos en cuenta al momento de aplicar otras técnicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cZVZ9cI9JGk"
   },
   "source": [
    "Es posible definir una función y pasarla a pandas para que la aplique en todas las filas de cierta columna. El resultado se puede guardar en una nueva columna del dataframe de pandas, por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y2jJ7XEq9JGp"
   },
   "outputs": [],
   "source": [
    "def acentos(text):\n",
    "    \"\"\"\n",
    "    Recibe un texto y lo devuelve sustituyendo caracteres por su versión sin acentos\n",
    "    \"\"\"\n",
    "    return unidecode.unidecode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0R7aT1i39JG1"
   },
   "outputs": [],
   "source": [
    "df_devel['texto_limpio'] = df_devel[1].apply(acentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "xtaNii8e9JG-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estos dias tratare de hacer deporte con mis amigos y desconectar.\n"
     ]
    }
   ],
   "source": [
    "# proceso solo el primer tweet\n",
    "\n",
    "for tweet in df_devel['texto_limpio'].values[:1]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "l1Y64dY_9JHH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estos dias tratare de hacer deporte con mis amigos y desconectar.']\n"
     ]
    }
   ],
   "source": [
    "oracion = df_devel['texto_limpio'].values[:1]\n",
    "print(oracion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "g0fhEa6i9JHU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estos dias tratare de hacer deporte con mis amigos y desconectar.'\n",
      " 'Un mensaje especial para un luchador como Eric Abidal. Toda la fuerza para tu recuperacion. Estamos con vos!'\n",
      " 'Chicxs nunca idealiceis demasiado a una persona, que luego os da mg en facebook y rompeis un espejo de la emocion '\n",
      " '@wkCArlos yo soy igual Jajajaja trato de evitarlo pero no lo logro'\n",
      " 'Y yo mientras comere palomitas mientras quedais retratados porque, ay, es lo que pasa cuando usas el activismo como un arma '\n",
      " 'Lo bueno: el gato regreso. Lo malo: creo que es del vecino y no me lo puedo dejar.'\n",
      " 'Recuerdo a Garzon ,bermejo,la fiscal,el poli de la judicial cazando gratis con Correa en el calabozo...'\n",
      " 'Llena de tristeza que victimas del terrorismo como #Pilar Manjon pretendan boicotear el trabajo de la justicia en el #11M #11Mconlasvictimas'\n",
      " 'RT @Ciutadans_Cs: A las 13h, no te pierdas a Ines Arrimadas en la tertulia \"La Alternativa de Cope Bcn #CsTeam'\n",
      " 'Fraga sera velado en su domicilio este lunes y el martes sera trasladado a Perbes(Lugo) donde sera enterrado. Es la intencion de la familia.']\n"
     ]
    }
   ],
   "source": [
    "#procesar los 10 primeros\n",
    "\n",
    "print(df_devel['texto_limpio'].values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Cc9Isra9JHf"
   },
   "source": [
    "En el caso de sustituir expresiones pueden usarse expresiones regulares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gmgERHM_9JHj"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def hashtags(text):\n",
    "    \"\"\"\n",
    "    Sustituye los hashtags con la palabra HASHTAG\n",
    "    \"\"\"\n",
    "    return re.sub('\\s([#][\\w_-]+)', ' HASHTAG ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kteTEnkV9JHr"
   },
   "source": [
    "Se aplica la función sobre la columna texto_limpio de manera de acumular las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "w0dIPG929JHu"
   },
   "outputs": [],
   "source": [
    "df_devel['texto_limpio'] = df_devel[1].apply(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "TGHNbwEF9JH0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estos días trataré de hacer deporte con mis amigos y desconectar.'\n",
      " 'Un mensaje especial para un luchador como Eric Abidal. Toda la fuerza para tu recuperación. Estamos con vos!'\n",
      " 'Chicxs nunca idealicéis demasiado a una persona, que luego os da mg en facebook y rompéis un espejo de la emoción '\n",
      " '@wkCArlos yo soy igual Jajajaja trató de evitarlo pero no lo logro'\n",
      " 'Y yo mientras comeré palomitas mientras quedáis retratados porque, ay, es lo que pasa cuando usas el activismo como un arma '\n",
      " 'Lo bueno: el gato regresó. Lo malo: creo que es del vecino y no me lo puedo dejar.'\n",
      " 'Recuerdo a Garzon ,bermejo,la fiscal,el poli de la judicial cazando gratis con Correa en el calabozo...'\n",
      " 'Llena de tristeza que víctimas del terrorismo como HASHTAG  Manjón pretendan boicotear el trabajo de la justicia en el HASHTAG  HASHTAG '\n",
      " 'RT @Ciutadans_Cs: A las 13h, no te pierdas a Inés Arrimadas en la tertulia \"La Alternativa de Cope Bcn HASHTAG '\n",
      " 'Fraga sera velado en su domicilio este lunes y el martes sera trasladado a Perbes(Lugo) donde será enterrado. Es la intención de la familia.']\n"
     ]
    }
   ],
   "source": [
    "# Aplicarlo a los 10 primeros tweets\n",
    "print(df_devel['texto_limpio'].values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_ot92EB9JH9"
   },
   "source": [
    "Hay que hacer lo propio con las mentions (@), con las URL, simbolos de puntuación y las cifras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1Q_ellfN9JIB"
   },
   "outputs": [],
   "source": [
    "def mentions(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return re.sub('(^@| @)(\\w|\\d|_)+ ','MENTION ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hZYxYa6X9JIN"
   },
   "outputs": [],
   "source": [
    "def url(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return re.sub(' ((https?://|www\\.)\\S+|\\S+\\.com)( |\\.)',' URL ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9l5ZS93S9JIY"
   },
   "outputs": [],
   "source": [
    "def numeros(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return re.sub(' \\d+(\\.\\d+)?\\.? ',' NUMBER ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DblSmqZb9JIg"
   },
   "outputs": [],
   "source": [
    "def puntuacion(text):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return re.sub('[.,!?:;\"]',' PUNCT',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xicmMV_59JIm"
   },
   "source": [
    "Pueden aplicarse las transformaciones de forma encadenada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Mvq0IwQ59JIo"
   },
   "outputs": [],
   "source": [
    "df_devel['texto_limpio'] = df_devel[1].apply(acentos).apply(hashtags).apply(mentions).apply(url).apply(numeros).apply(puntuacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "4Q1qBCcA9JIw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estos dias tratare de hacer deporte con mis amigos y desconectar PUNCT'\n",
      " 'Un mensaje especial para un luchador como Eric Abidal PUNCT Toda la fuerza para tu recuperacion PUNCT Estamos con vos PUNCT'\n",
      " 'Chicxs nunca idealiceis demasiado a una persona PUNCT que luego os da mg en facebook y rompeis un espejo de la emocion '\n",
      " 'MENTION yo soy igual Jajajaja trato de evitarlo pero no lo logro'\n",
      " 'Y yo mientras comere palomitas mientras quedais retratados porque PUNCT ay PUNCT es lo que pasa cuando usas el activismo como un arma '\n",
      " 'Lo bueno PUNCT el gato regreso PUNCT Lo malo PUNCT creo que es del vecino y no me lo puedo dejar PUNCT'\n",
      " 'Recuerdo a Garzon  PUNCTbermejo PUNCTla fiscal PUNCTel poli de la judicial cazando gratis con Correa en el calabozo PUNCT PUNCT PUNCT'\n",
      " 'Llena de tristeza que victimas del terrorismo como HASHTAG  Manjon pretendan boicotear el trabajo de la justicia en el HASHTAG  HASHTAG '\n",
      " 'RT @Ciutadans_Cs PUNCT A las 13h PUNCT no te pierdas a Ines Arrimadas en la tertulia  PUNCTLa Alternativa de Cope Bcn HASHTAG '\n",
      " 'Fraga sera velado en su domicilio este lunes y el martes sera trasladado a Perbes(Lugo) donde sera enterrado PUNCT Es la intencion de la familia PUNCT']\n"
     ]
    }
   ],
   "source": [
    "# verificarlo con los 10 primeros tweets\n",
    "print(df_devel['texto_limpio'].values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3xmOacL9JJQ"
   },
   "source": [
    "Hay que tener cuidado por si exiten tweets con líneas en blanco\n",
    "¿Cómo lo resolvería?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "1nZjRMze9JJU"
   },
   "outputs": [],
   "source": [
    "df_devel['texto_limpio'] = df_devel['texto_limpio'].apply(lambda text : re.sub(r'\\n\\s*4\\n','\\n',text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5qeQpMi9JJc"
   },
   "source": [
    "### Trabajo con el tokenizador de NLTK, el punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "wzYdzVmD9JJg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Bruno/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# es importante para tokenizar (palabras u oraciones) bajar el paquete punkt\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "j6dXC7B79JJo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hoy', 'es', 'un', 'lindo', 'dia']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# como invocar al tokenizador de palabras\n",
    "\n",
    "nltk.word_tokenize('Hoy es un lindo dia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "39lc2x7P9JJx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estos',\n",
       " 'dias',\n",
       " 'tratare',\n",
       " 'de',\n",
       " 'hacer',\n",
       " 'deporte',\n",
       " 'con',\n",
       " 'mis',\n",
       " 'amigos',\n",
       " 'y',\n",
       " 'desconectar',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacerlo para el primer tweet\n",
    "nltk.word_tokenize(df_devel['texto_limpio'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "-FNQbyA-9JJ2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola amigos.',\n",
       " 'Gracias por venir.',\n",
       " 'Saludos.',\n",
       " 'Qué lindoo!!',\n",
       " 'Será verdad?',\n",
       " 'Tal vez si']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# como invocar al tokenizador de oraciones\n",
    "\n",
    "nltk.sent_tokenize('Hola amigos. Gracias por venir. Saludos. Qué lindoo!! Será verdad? Tal vez si')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5qXzt6B9JJ8"
   },
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KT0JT0PL9JJ_"
   },
   "source": [
    "Tokenizamos con Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "PuTDcn0X9JKC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Downloading es_core_web_md-1.0.0/es_core_web_md-1.0.0.tar.gz\n",
      "\n",
      "Collecting https://github.com/explosion/spacy-models/releases/download/es_core_web_md-1.0.0/es_core_web_md-1.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_web_md-1.0.0/es_core_web_md-1.0.0.tar.gz (395.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 395.1MB 799kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<2.0.0,>=1.8.0 in /Users/Bruno/anaconda/lib/python3.5/site-packages (from es-core-web-md==1.0.0)\n",
      "Installing collected packages: es-core-web-md\n",
      "  Running setup.py install for es-core-web-md ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
      "\u001b[?25hSuccessfully installed es-core-web-md-1.0.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "\n",
      "    /Users/Bruno/anaconda/lib/python3.5/site-packages/es_core_web_md/es_core_web_md-1.0.0\n",
      "    -->\n",
      "    /Users/Bruno/anaconda/lib/python3.5/site-packages/spacy/data/es_core_web_md\n",
      "\n",
      "    You can now load the model via spacy.load('es_core_web_md').\n",
      "\n",
      "Hoy\n",
      "puede\n",
      "ser\n",
      "un\n",
      "gran\n",
      "día\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# con la bilbioteca spacy también se puede tokenizar\n",
    "# !python -m spacy download es_core_news_md\n",
    "!python -m spacy download es_core_web_md\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('es_core_web_md')\n",
    "\n",
    "doc = nlp(\"Hoy puede ser un gran día.\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXiMhv3p9JKV"
   },
   "source": [
    "Spacy aplica un pipeline de PLN a los textos, tokenizador, stemming, pos tagger, ner, vectores de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wEWX24SH9JKX"
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for tweet in df_devel['texto_limpio'].values[:10]:\n",
    "    doc = nlp(tweet)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "d7z2ldcB9JKf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraga PROPN ROOT\n",
      "sera AUX amod\n",
      "velado VERB ROOT\n",
      "en ADP case\n",
      "su DET det\n",
      "domicilio NOUN obl\n",
      "este DET det\n",
      "lunes NOUN appos\n",
      "y CONJ cc\n",
      "el DET det\n",
      "martes NOUN conj\n",
      "sera NOUN obj\n",
      "trasladado ADJ amod\n",
      "a ADP case\n",
      "Perbes(Lugo PROPN obj\n",
      ") PUNCT punct\n",
      "donde PRON obl\n",
      "sera AUX aux\n",
      "enterrado VERB acl\n",
      "PUNCT PROPN nsubj\n",
      "  SPACE \n",
      "Es AUX cop\n",
      "la DET det\n",
      "intencion NOUN advcl\n",
      "de ADP case\n",
      "la DET det\n",
      "familia NOUN nmod\n",
      "PUNCT PROPN appos\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "DVlHXsEa9JKm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraga fraga PROPN PROPN___ ROOT Xxxxx True False\n",
      "sera sera AUX AUX__Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbForm=Fin amod xxxx True True\n",
      "velado velado VERB VERB__Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part ROOT xxxx True False\n",
      "en en ADP ADP__AdpType=Prep case xx True True\n",
      "su su DET DET__Number=Sing|Person=3|Poss=Yes|PronType=Prs det xx True True\n",
      "domicilio domicilio NOUN NOUN__Gender=Masc|Number=Sing obl xxxx True False\n",
      "este este DET DET__Gender=Masc|Number=Sing|PronType=Dem det xxxx True True\n",
      "lunes lunes NOUN NOUN__AdvType=Tim appos xxxx True False\n",
      "y y CONJ CCONJ___ cc x True False\n",
      "el el DET DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art det xx True True\n",
      "martes martes NOUN NOUN__AdvType=Tim conj xxxx True False\n",
      "sera sera NOUN NOUN___ obj xxxx True True\n",
      "trasladado trasladado ADJ ADJ__Gender=Masc|Number=Sing|VerbForm=Part amod xxxx True False\n",
      "a a ADP ADP__AdpType=Prep case x True False\n",
      "Perbes(Lugo perbes(lugo PROPN PROPN___ obj Xxxxx(Xxxx False False\n",
      ") ) PUNCT PUNCT__PunctSide=Fin|PunctType=Brck punct ) False False\n",
      "donde donde PRON PRON__PronType=Rel obl xxxx True True\n",
      "sera sera AUX AUX__Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbForm=Fin aux xxxx True True\n",
      "enterrado enterrado VERB VERB__Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part acl xxxx True False\n",
      "PUNCT punct PROPN PROPN___ nsubj XXXX True False\n",
      "    SPACE SP    False False\n",
      "Es es AUX AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin cop Xx True True\n",
      "la la DET DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art det xx True True\n",
      "intencion intencion NOUN NOUN__Gender=Fem|Number=Sing advcl xxxx True False\n",
      "de de ADP ADP__AdpType=Prep case xx True True\n",
      "la la DET DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art det xx True True\n",
      "familia familia NOUN NOUN__Gender=Fem|Number=Sing nmod xxxx True False\n",
      "PUNCT punct PROPN PROPN___ appos XXXX True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "M7qNBlEe9JKy"
   },
   "outputs": [],
   "source": [
    "tokens = nlp(\"Perros y gatos se pelean por los peces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "N-qwNnJt9JK5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perros Perros -3.36589109172e-21\n",
      "Perros y 0.0401328898052\n",
      "Perros gatos 3.76877257979e-21\n",
      "Perros se 0.0\n",
      "Perros pelean -0.0959286250882\n",
      "Perros por -0.0418655873622\n",
      "Perros los 0.0388161976578\n",
      "Perros peces 0.0\n",
      "y Perros 0.0401328898052\n",
      "y y -1.4062461959e-21\n",
      "y gatos 0.0449366098082\n",
      "y se 0.0\n",
      "y pelean 0.0\n",
      "y por -1.4669594752e-21\n",
      "y los -4.6282132749e+17\n",
      "y peces -1.8750773402e-21\n",
      "gatos Perros 3.76877257979e-21\n",
      "gatos y 0.0449366098082\n",
      "gatos gatos 0.0\n",
      "gatos se -2.32256748419e-21\n",
      "gatos pelean 0.0\n",
      "gatos por -8.64722546825e+17\n",
      "gatos los -0.0434623157429\n",
      "gatos peces 0.0\n",
      "se Perros 0.0\n",
      "se y -1.34075405865e-21\n",
      "se gatos -0.0428438079748\n",
      "se se 4.34987047207e+17\n",
      "se pelean -0.0591175775974\n",
      "se por 0.0258003500756\n",
      "se los 0.0\n",
      "se peces 0.0\n",
      "pelean Perros -0.0959286250882\n",
      "pelean y 0.0\n",
      "pelean gatos 0.0\n",
      "pelean se -0.0591175775974\n",
      "pelean pelean 8.03446448215e-21\n",
      "pelean por 0.0\n",
      "pelean los 0.0\n",
      "pelean peces -1.52512843332e+18\n",
      "por Perros -0.0418655873622\n",
      "por y -1.4669594752e-21\n",
      "por gatos -8.64722546825e+17\n",
      "por se 0.0258003500756\n",
      "por pelean 0.0\n",
      "por por -1.53029398989e-21\n",
      "por los -0.026172812695\n",
      "por peces 0.0360824205483\n",
      "los Perros 0.0388161976578\n",
      "los y -4.6282132749e+17\n",
      "los gatos -8.0173821536e+17\n",
      "los se 0.0\n",
      "los pelean 0.0\n",
      "los por -0.026172812695\n",
      "los los -0.0242664473339\n",
      "los peces 0.0\n",
      "peces Perros 0.0\n",
      "peces y -0.0345890718131\n",
      "peces gatos 3.24816742683e-21\n",
      "peces se 0.0\n",
      "peces pelean -1.52512843332e+18\n",
      "peces por 0.0360824205483\n",
      "peces los 0.0\n",
      "peces peces 0.0461207894924\n"
     ]
    }
   ],
   "source": [
    "# Permite verificar con los vectores de palabras cuan cerca están 2 palabras utilizando\n",
    "# el corpus de noticias de la wikipedia\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "CBZGZ9959JK9"
   },
   "source": [
    "Hacerlo con otra oración y analizar el resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dyJb9JYR9JK_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGu0vClf9JLH"
   },
   "source": [
    "### Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnUL9lJ_9JLJ"
   },
   "source": [
    "Interesa conocer la longitud de los textos, se puede crear una nueva columna con ese valor usando la funcion len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JFcrAm5_9JLK"
   },
   "outputs": [],
   "source": [
    "df_devel['largo_texto'] = df_devel['texto_limpio'].apply(len)\n",
    "# df_devel['largo_texto'] = df_devel[1].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "u0vEBf0Y9JLP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>texto_limpio</th>\n",
       "      <th>largo_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187437263205044224</td>\n",
       "      <td>Estos días trataré de hacer deporte con mis am...</td>\n",
       "      <td>P</td>\n",
       "      <td>Estos dias tratare de hacer deporte con mis am...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180438913880571904</td>\n",
       "      <td>Un mensaje especial para un luchador como Eric...</td>\n",
       "      <td>P</td>\n",
       "      <td>Un mensaje especial para un luchador como Eric...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771051726694744064</td>\n",
       "      <td>Chicxs nunca idealicéis demasiado a una person...</td>\n",
       "      <td>N</td>\n",
       "      <td>Chicxs nunca idealiceis demasiado a una person...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>810700953620021248</td>\n",
       "      <td>@wkCArlos yo soy igual Jajajaja trató de evita...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>MENTION yo soy igual Jajajaja trato de evitarl...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>769894353389162497</td>\n",
       "      <td>Y yo mientras comeré palomitas mientras quedái...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y yo mientras comere palomitas mientras quedai...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1    2  \\\n",
       "0  187437263205044224  Estos días trataré de hacer deporte con mis am...    P   \n",
       "1  180438913880571904  Un mensaje especial para un luchador como Eric...    P   \n",
       "2  771051726694744064  Chicxs nunca idealicéis demasiado a una person...    N   \n",
       "3  810700953620021248  @wkCArlos yo soy igual Jajajaja trató de evita...  NEU   \n",
       "4  769894353389162497  Y yo mientras comeré palomitas mientras quedái...    N   \n",
       "\n",
       "                                        texto_limpio  largo_texto  \n",
       "0  Estos dias tratare de hacer deporte con mis am...           70  \n",
       "1  Un mensaje especial para un luchador como Eric...          123  \n",
       "2  Chicxs nunca idealiceis demasiado a una person...          119  \n",
       "3  MENTION yo soy igual Jajajaja trato de evitarl...           64  \n",
       "4  Y yo mientras comere palomitas mientras quedai...          134  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devel.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkQvgFYs9JLV"
   },
   "source": [
    "La función describe de pandas brinda estadisticas sobre las columnas númericas, lo que permite saber por ejemplo que el largo primedio de los textos es 98 carácteres y el máximo es 201."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "WtiJQj2B9JLX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>largo_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.133000e+03</td>\n",
       "      <td>1133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.919435e+17</td>\n",
       "      <td>107.505737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.006609e+17</td>\n",
       "      <td>42.293932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.424945e+17</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.624782e+17</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.795517e+17</td>\n",
       "      <td>113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.706669e+17</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.194038e+17</td>\n",
       "      <td>403.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0  largo_texto\n",
       "count  1.133000e+03  1133.000000\n",
       "mean   3.919435e+17   107.505737\n",
       "std    3.006609e+17    42.293932\n",
       "min    1.424945e+17    11.000000\n",
       "25%    1.624782e+17    73.000000\n",
       "50%    1.795517e+17   113.000000\n",
       "75%    7.706669e+17   141.000000\n",
       "max    8.194038e+17   403.000000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devel.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5x7vMDek9JLc"
   },
   "source": [
    "Es posible localizar la fila donde se encuentra el tweet más largo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "BM0DrLxw9JLe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Todo estaba bien hasta que me desilusionaron  PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCTme siento herida  PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT PUNCTque dolor  PUNCT PUNCT PUNCT PUNCT PUNCT PUNCT  PUNCT PUNCT PUNCT PUNCT PUNCT'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_devel.loc[df_devel['largo_texto'].idxmax()]['texto_limpio']\n",
    "df_devel.loc[df_devel['largo_texto'].idxmax()]['texto_limpio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "UotiT6fQDhDN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Todo estaba bien hasta que me desilusionaron .....................me siento herida .......................que dolor ...... .....'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devel[1][505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Que chiva pasar debajo del puente de la platina PUNCT siempre he querido  PUNCT PUNCT PUNCTes en serio PUNCT'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devel['texto_limpio'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devel['largo_texto'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "1a2SirUC9JFH",
    "fnkh6nwt9JGf",
    "Z5qeQpMi9JJc",
    "F5qXzt6B9JJ8",
    "XGu0vClf9JLH"
   ],
   "name": "Laboratorio1 - Letra.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
