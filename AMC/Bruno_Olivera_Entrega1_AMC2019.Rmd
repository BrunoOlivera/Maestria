---
title: "Entrega 1"
author: "Bruno Olivera"
date: "10/5/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Practico 2: Regresión lineal múltiple
## Ejercicio 1

```{r 1}
set.seed(2019)

n <- 1000

x1 <- sort(runif(n))
x2 <- sort(runif(n))
x3 <- sort(runif(n))
y  <- 3 + 2*x1 -2*x2 + x3 + rnorm(n, sd = 1)
```
a)
```{r 1-a}
# generamos la matriz de datos
data <- cbind(x1,x2,x3,y)
```
b)
```{r 1-b}
x0 <- rep(1, n)
Xdata <- cbind(x1,x2,x3)
X <- cbind(x0,Xdata)

# estimamos los parámetros Beta
Beta <- solve((t(X)%*%X))%*%t(X)%*%y
```
```{r 1-b-names, echo=FALSE}
row.names(Beta) <- c('Beta_0','Beta_1','Beta_2','Beta_3')
```
```{r}
Beta

# damos intervlos de confianzo para las estimaciones
model <- lm(y ~ Xdata)
intervals <- confint(model)
```
```{r 1-b-names-intevals, echo=FALSE}
row.names(intervals) <- c('Beta_0','Beta_1','Beta_2','Beta_3')
```
```{r 1-b-intervals}
intervals
```
c)
```{r 1-c-aux, echo=FALSE}
# función para clacular el vif
vif_calc<-function(Xmat){
  VIF<-numeric()
  for(i in 1:ncol(Xmat)){
    Xmat_Y<-Xmat[,i]
    dataMAT<-cbind(Xmat_Y, Xmat[,-i])
    R2<-summary(lm(Xmat_Y~.,data=dataMAT, na.action="na.exclude"))$r.squared
    VIF[i]<-1/(1-R2)
  }
  names(VIF)<-colnames(Xmat)
  return(VIF)
}
```
```{r 1-c, warning=FALSE}
# estimamos los parámetros Beta y calculamos sus varianzas
# para cada valor de tau
results <- matrix(ncol=8, nrow=5)
VIFs <- NULL
B_estimates <- NULL
tau <- c(0, .01, .1, 1, 10)

for(i in 1:5){
  x2_new <- x1 + rnorm(n, mean=0, sd=tau[i])
  Xdata_new <- cbind(x1,x2_new,x3)
  X_new <- cbind(x0,Xdata_new)
  if(tau[i] != 0) {
    B_estimates <- solve((t(X_new)%*%X_new))%*%t(X_new)%*%y
  }
  model_new <- lm(y ~ Xdata_new)
  summary_model <- summary(model_new)
  
  # para el caso de tau = 0 tenemos que sacar los estimadores del
  # modelo porque la matriz (X'X) no es invertible
  if(tau[i] == 0) {
    B_estimates[1] <- summary_model$coefficients[,1][1]
    B_estimates[2] <- summary_model$coefficients[,1][2]
    B_estimates[3] <- NA
    B_estimates[4] <- summary_model$coefficients[,1][3]
  }
  
  # calculamos la variación de los Betas mediante el cuadrado
  # del Std. Error devuelto por el modelo
  var_B0_1 = (summary_model$coefficients[,2]**2)[1]
  var_B1_1 = (summary_model$coefficients[,2]**2)[2]
  if(tau[i] != 0){
    var_B2_1 = (summary_model$coefficients[,2]**2)[3]
    var_B3_1 = (summary_model$coefficients[,2]**2)[4]
  }else{
    var_B2_1 = NA
    var_B3_1 = (summary_model$coefficients[,2]**2)[3]
  }
  
  if(tau[i] != 0) {
    # aproximamos la variación del modelo y calculamos la matriz var*inv(X'X)
    var_model_new = (sum((model_new$residuals)**2)/(n-4))*solve((t(X_new)%*%X_new))
    
    # calculamos la variación de los beta como la diagonal de la matriz anterior 
    var_B0_2 = var_model_new[1,1]
    var_B1_2 = var_model_new[2,2]
    var_B2_2 = var_model_new[3,3]
    var_B3_2 = var_model_new[4,4]
    
    # controlamos que sean iguales ambas formas de calcular las varianzas
    assertthat::are_equal(var_B0_1,var_B0_2)
    assertthat::are_equal(var_B2_1,var_B1_2)
    assertthat::are_equal(var_B3_1,var_B2_2)
    assertthat::are_equal(var_B3_1,var_B3_2)
  }
  
  newRow.data <- c(B_estimates[1],
                   B_estimates[2],
                   B_estimates[3],
                   B_estimates[4],
                   var_B0_1,
                   var_B1_1,
                   var_B2_1,
                   var_B3_1)
  
  results[i,] = newRow.data
  
  # calculamos el VIF y lo guardamos para la parte d)
  VIFs <- rbind(VIFs,vif_calc(data.frame(Xdata_new)))
}
```
```{r 1-c-names, echo=FALSE}
row.names(results) <- c('  0','.01',' .1','  1',' 10')
colnames(results)  <- c('Beta_0','Beta_1','Beta_2','Beta_3',
                        'Var_Beta_0','Var_Beta_1','Var_Beta_2','Var_Beta_3')
```
```{r 1-c-results}
# resultados
results
```
d)
```{r 1-d-names, echo=FALSE}
row.names(VIFs) <- c('  0','.01',' .1','  1',' 10')
```
```{r 1-d}
# calculamos los VIFs
VIFs
```

## Ejercicio 2
