{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 9 (Detección de Humor con Word Embeddings)\n",
    "\n",
    "En esta clase utilizaremos un conjunto de vectores de palabras pre-entrenados y modelos de redes neuronales para detectar humor en textos cortos. A lo largo de este *notebook* definiremos, entrenaremos y evaluaremos modelos neuronales con un conjunto de datos impartido y vectores pre-entrenados.\n",
    "\n",
    "## Cargar Word Embeddings Y Corpus\n",
    "\n",
    "Primero cargaremos el repertorio de vectores y el conjunto de datos. \n",
    "\n",
    "Ejecute el siguiente bloque de código para importar un conjunto de paquetes que serán de utilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import IPython\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "El repertorio de vectores de palabras se encuentra en el archivo **aaa_humor_vectores.txt**, vamos a descargarlo y cargarlo en memoria en una estructura que sea conveniente.\n",
    "\n",
    "Descargue el archivo de: https://www.fing.edu.uy/~mathiase/cpap/aaa_humor_vectores.txt\n",
    "\n",
    "**Nota:**\n",
    "Este archivo de vectores fue generado utilizando el modelo para el español disponible en: <br>\n",
    "https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.bin.gz\n",
    "\n",
    "\n",
    "** Ejecute el siguiente bloque para cargar el conjunto de vectores. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_vectors(filename):\n",
    "  f = open(filename, 'r')\n",
    "  wd2ind, X, ind = dict(), list(), -1\n",
    "  for l in f:\n",
    "    l_split = l.split()\n",
    "    word, vector = l_split[0], list(map(float, l_split[1:]))\n",
    "    wd2ind[word] = ind = ind + 1      \n",
    "    X.append(vector)\n",
    "  f.close()\n",
    "  X.append([0]*len(X[0]))  # vector for <UNK> words \n",
    "  X =  np.array(X)  # convert to numpy.array\n",
    "  wd2vect = lambda x: X[wd2ind.get(x, -1)]\n",
    "  wd2vect.name, wd2vect.dim, wd2vect.X = filename, len(X[0]), X\n",
    "  wd2vect.ind = wd2ind \n",
    "  return wd2vect\n",
    "\n",
    "vectores = load_vectors('./aaa_humor_vectores.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el siguiente bloque para desplegar la cantidad de vectores cargados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(vectores.ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el siguiente bloque para desplegar la dimensión de los vectores cargados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectores.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el siguiente bloque para obtener el vector de la palabra lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectores('lenguaje')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus de Humor\n",
    "\n",
    "El corpus de humor está fraccionado en tres conjuntos: entrenamiento (*train*), validación (*val*) y evaluación (*test*). Los conjuntos son impartidos en los archivos **data_train.csv**, **data_val.csv** y **data_test.csv**.\n",
    "\n",
    "Primero cargaremos los archivos y los segmentaremos en palabras (*tokenize*).\n",
    "\n",
    "** Complete la asignación que falta en el bloque siguiente para cargar el corpus de humor. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "\n",
    "# función para segmentar la entrada en palabras\n",
    "tokenizer = lambda x: regexp_tokenize(x, pattern='[^\\w]|\\w+')\n",
    "\n",
    "def load_corpus(csvfile):\n",
    "    corpus = list()\n",
    "    with open(csvfile) as f:\n",
    "        freader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        next(freader, None)  # para escapar los headers\n",
    "        for row in freader:\n",
    "            c_0 = # ####### COMPLETAR LA ASIGNACIÓN DE c_0 #######\n",
    "            c_1 = row[1]\n",
    "            r = [c_0, c_1]\n",
    "            corpus.append(r)\n",
    "    return corpus\n",
    "            \n",
    "train = load_corpus('./data_train.csv')\n",
    "val = load_corpus('./data_val.csv')\n",
    "test = load_corpus('./data_test.csv')\n",
    "\n",
    "print('# train:',len(train)) \n",
    "print('# val:',len(val)) \n",
    "print('# test:',len(test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización de la entrada\n",
    "\n",
    "Ahora utilizando los vectores y los conjuntos de datos, vamos a construir una matriz Nx(L\\*D) para cada conjunto con los vectores correspondientes a las palabras de la entrada, donde N es la cantidad de elementos del conjunto, L el largo máximo de oración y D la dimensión de los vectores de palabras. Además, vamos a construir un vector de dimensión N con las salidas esperadas para cada conjunto.\n",
    "\n",
    "En resumen, vamos a tener:\n",
    "\n",
    "- X_train, y_train\n",
    "- X_val, y_val\n",
    "- X_test, y_test\n",
    "\n",
    "para los conjuntos train, val y test, respectivamente.\n",
    "\n",
    "\n",
    "Pero antes vamos a elegir el largo máximo de oración para armar las formas matriciales de nuestros conjuntos de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elección de largo máximo de oración\n",
    "\n",
    "Para elegir el largo máximo de oración veamos una distribución de los largos de oración en los conjuntos train y val.\n",
    "\n",
    "Implemente una función que recorra un conjunto de datos y devuelva:\n",
    "\n",
    "- un diccionario python con (cant. palabras, cant. entradas) contando la cantidad de palabras de las entradas. Almacene entradas de 10 en 10, es decir [10,20,30,...], donde por ej. 20 se interpreta como entradas de 11 a 20 palabras. (Nombre de variable: **lenhist**)\n",
    "\n",
    "- el largo (cantidad de palabras) de la entrada de largo máximo y la entrada. (Nombres de variables: **maxlen** y **maxin**)\n",
    "\n",
    "\n",
    "** Complete las partes que faltan en el siguiente bloque de código. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def len_histogram(corpus):\n",
    "    maxlen = 0\n",
    "    maxin = \"\"\n",
    "    lenhist = dict()\n",
    "\n",
    "    for t in corpus:\n",
    "        # ##### COMPLETE EL CUERPO DEL FOR PARA ASIGNAR LAS VARIABLES PEDIDAS #####\n",
    "\n",
    "    return lenhist, maxlen, maxin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En los siguientes bloques de código, usando los conjuntos de entrenamiento y validación, se realiza lo siguiente:**\n",
    "\n",
    "**1 -** Se imprime la cantaidad de palabras y la entrada, de la entrada con máxima cantidad de palabras, para los conjuntos train y val. <br>\n",
    "**2 -** Se grafica un histograma con la cantidad de entradas por cantidad de palabras de 10 en 10, para los conjuntos train y val. \n",
    "\n",
    "** Ejecute los bloques que siguen que utilizan la función 'len_histogram'. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lenhist_train, maxlen_train, maxin_train = len_histogram(train)\n",
    "lenhist_val, maxlen_val, maxin_val = len_histogram(val)\n",
    "print('Train: ', maxlen_train, maxin_train )\n",
    "print('Val: ', maxlen_val, maxin_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram(hist):\n",
    "    indxs = list(range(10,(len(hist)+1)*10, 10))\n",
    "    plt.bar(range(len(hist)), [hist.get(i,0) for i in indxs], align='center')\n",
    "    plt.xticks(range(len(hist)), indxs)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Train:\")\n",
    "plot_histogram(lenhist_train)\n",
    "print(\"Test:\")\n",
    "plot_histogram(lenhist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Versiones vectorizadas de los conjuntos de entrenamiento, validación y evaluación.**\n",
    "\n",
    "Considere la función **corpus_vectorize** para construir la representación matricial mencionada anterioremente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 30\n",
    "\n",
    "def corpus_vectorize(corpus, vecs, max_words):\n",
    "    X, y = [], []\n",
    "    for r in corpus:\n",
    "        s = r[0][:max_words] + ['###PADDING###'] * (max_words-len(r[0]))  # agrega padding o corta la oración\n",
    "        row = []\n",
    "        for w in s:\n",
    "            if len(vectors(w)) == vectors.dim:  # control para la dimensión\n",
    "                row.append(vectors(w))\n",
    "            else:\n",
    "                row.append(vectors('###PADDING###'))\n",
    "        X.append(row)\n",
    "        y.append(r[1])\n",
    "    X = np.array(X, dtype='float64')\n",
    "    y = np.array(y, dtype='int32')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = corpus_vectorize(train, vectors, max_words)\n",
    "X_val, y_val = corpus_vectorize(val, vectors, max_words)\n",
    "X_test, y_test = corpus_vectorize(test, vectors, max_words)\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape) \n",
    "print(\"X_val.shape: \", X_val.shape) \n",
    "print(\"X_test.shape: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de Modelo y Entrenamiento\n",
    "\n",
    "En esta parte vamos a definir y entrenar modelos utilizando Keras.\n",
    "\n",
    "Para realizar las partes se debe utilizar la referencia de keras: \n",
    "\n",
    "https://keras.io/layers/recurrent/\n",
    "\n",
    "** Utilice el siguiente bloque de código para definir un modelo **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, ...\n",
    "\n",
    "# ##### COMPLETAR RESTO DE LA DEFINICION DEL MODELO #####\n",
    "               \n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Compilar el modelo definido **\n",
    "\n",
    "Utilice el siguiente bloque de código para compilar el modelo. Puede modificar el código impartido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Entrenar el modelo compilado **\n",
    "\n",
    "Complete el siguiente bloque de código para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, ...\n",
    "          \n",
    "# ### COMPLETAR ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluar el modelo entrenado en el conjunto de validación **\n",
    "\n",
    "Evaluar el modelo usando X_val e y_val con el método *evaluate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluación con Precision, recall y F **\n",
    "\n",
    "Considere la siguiente función para calcular las medidas P, R y F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_acc_p_r_f(model, X,y):\n",
    "    # from: https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/\n",
    "    yhat_classes = model.predict_classes(X, verbose=0)[:, 0]\n",
    "    \n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(y, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(y, yhat_classes)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(y, yhat_classes)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(y, yhat_classes)\n",
    "    print('F1 score: %f' % f1)\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Utilice la función anterior para calcular P, R y F en el conjunto de validación. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_acc_p_r_f(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de hiperparámetros\n",
    "\n",
    "Una vez vista la secuencia completa para definir, compilar, entrenar y evaluar un modelo; vamos a determinar una buena configuración de hiperparámetros.\n",
    "\n",
    "Debemos entener en cuenta hiperparámetros en cuanto a:\n",
    "\n",
    "- Estructura del modelo: cantidad y tipo de capas, cantidad de nueronas\n",
    "- Entrenamiento: método de entrenamiento, parámetros del métodos (learning rate, etc.)\n",
    "- Regularizaciones: Dropout, Early Stopping\n",
    "- Otras: Capas Bidireccionales, Capas Convolutivas, Combinaciones\n",
    "\n",
    "\n",
    "Es elección de cada estudiante elegir una de las siguiente técnicas de entrenamiento:\n",
    "\n",
    "- Manual Search\n",
    "- Grid Search\n",
    "- Random Search\n",
    "\n",
    "** Utilice los bloques de código que considere necesarios para realizar la búsqueda de hiperparámetros y entrenamiento de su modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Búsqueda de hiperparámetros y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación\n",
    "\n",
    "Una vez encontrada una configuración adecuada de hiperparámetros haciendo uso del conjunto de validación, evaluamos el desempeño del modelo en los datos de evaluación.\n",
    "\n",
    "** Muestre el desempeño del modelo final en los datos de test en cuanto a Acc, P, R y F. **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluación del modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Probar con entradas definidas por el usuario\n",
    "\n",
    "Utilice lo visto anteriormente para ejecutar una entrada provista por el usuario con el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def es_humor(model, entrada):\n",
    "    # ### COMPLETAR ###\n",
    "    return False"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
