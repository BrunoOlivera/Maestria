{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales convolucionales\n",
    "\n",
    "En esta clase vamos a crear una red neuronal convolucional simple. \n",
    "\n",
    "Vamos a implementar algunas arquitecturas simples y entrenaremos con el conjunto de datos CIFAR-10.\n",
    "\n",
    "Primero vamos a importar los modulos necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar la base de datos\n",
    "\n",
    "Usaremos la base de datos CIFAR-10, la cual conciste en 60000 imágenes a color de 32x32. La base de datos está compuestas de 50000 imágenes de entrenamiento y 10000 de test.\n",
    "Es una colección de imágenes que contiene 10 clases diferentes. Las 10 clases diferentes representan aviones, automóviles, pájaros, gatos, venados, perros, ranas, caballos, barcos y camiones.\n",
    "\n",
    "A continuación se ve un ejemplo de algunas imágenes de la base de datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las variables que vamos a utilizar:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "num_classes = 10 \n",
    "epochs = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "  3350528/170498071 [..............................] - ETA: 6:47"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos algunas de las imágenes de la base de datos para familiarizarnos con la misma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(x_train[i])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores de los pixeles están en un rango de entre 0 y 255 para cada canal (rojo, verde y azul). Es una buena práctica normalizar los valores. \n",
    "\n",
    "Debido a que los valores son conocidos, podemos normalizar fácilmente el rango a valores entre 0 y 1 dividiendo cada valor por la observación máxima que es 255.\n",
    "\n",
    "Tenga en cuenta que los datos se cargan como enteros, por lo que debemos convertirlos en valores de punto flotante para realizar la división.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "x_train =\n",
    "x_test = \n",
    "x_train  /= \n",
    "x_test /= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudie el siguiente modelo, indicando que capas componen la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "cnn_n = define_model()\n",
    "cnn_n.summary()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Entrene el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit model\n",
    " \n",
    "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cnn.history queda el registro histórico de qué sucedió con la accuracy y loss durante el entrenamiento para ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots for training and testing process: loss and accuracy\n",
    " \n",
    "plt.figure(0)\n",
    "plt.plot(cnn.history['acc'],'r')\n",
    "plt.plot(cnn.history['val_acc'],'g')\n",
    "plt.xticks(np.arange(0, epochs + 1, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\" Accuracy \")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    " \n",
    "plt.figure(1)\n",
    "plt.plot(cnn.history['loss'],'r')\n",
    "plt.plot(cnn.history['val_loss'],'g')\n",
    "plt.xticks(np.arange(0, epochs + 1, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\" Loss   \")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora deberá mejorar el rendimiento de la red, para ello deberá experimentar con diferentes arquitecturas,  hiperparámetros, funciones de pérdida (loss) y optimizadores,\n",
    "\n",
    "Cosas que se pueden probar:\n",
    "    * Tamaño del filtro\n",
    "    * Número de filtros\n",
    "    * Tamaño del batch\n",
    "    * Arquitectura de la red: \n",
    "          - probar hacer una red más profunda. \n",
    "          - probar alguna de las siguientes arquitecturas: \n",
    "          \n",
    "            [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "            [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "            [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Completar\n",
    "def define_model():\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrene el modelo, definiendo los páramentros adecuados:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafique el registro histórico de qué sucedió con la accuracy y loss durante el entrenamiento para ambos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Completar"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
