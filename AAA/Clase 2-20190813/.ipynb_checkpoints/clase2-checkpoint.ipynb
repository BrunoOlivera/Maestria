{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 2 - Conceptos generales de clasificación\n",
    "\n",
    "En esta clase vamos a ver el clásico ejemplo del dataset de iris.\n",
    "Vamos a ver distintos métodos de aprendizaje, medio rápidamente y vamos a ver formas de evaluación.\n",
    "Primero chequeamos las librerías que vamos a utilizar y sus versiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.5.2\n",
      "IPython version: 5.1.0\n",
      "numpy version: 1.11.1\n",
      "scikit-learn version: 0.17.1\n",
      "matplotlib version: 1.5.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import IPython\n",
    "import platform\n",
    "\n",
    "print ('Python version:', platform.python_version())\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sklearn.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Para una aplicación de aprendizaje automático, necesitamos un dataset. Scikit tiene algunos de prueba. En particular, tiene el que queremos utilizar.\n",
    "Denotamos a __X__  como el conjunto de atributos e __y__ el conjunto de etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aquí deben importar el dataset\n",
    "\n",
    "X_iris =\n",
    "y_iris ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre es buena idea analizar el dataset antes de empezar a desarrollar. ¿Qué se puede decir de los datos? Es conveniente hacer un análisis de los atributos y de la clase objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar los primeros dos atributos, y los últimos dos atributos por separado, dibujando en función de la clase objetivo.\n",
    "Voy a dejar algunas partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure('sepal')\n",
    "#Pueden elegir otros colores si quieren\n",
    "colormarkers = [ ['red','s'], ['greenyellow','o'], ['blue','x']]\n",
    "for i, val in enumerate(set(y_iris)):\n",
    "#En px y py tienen que ir las clases que corresponden a cada etiqueta, \n",
    "#para poder graficar los elementos del dataset por color\n",
    "    \n",
    "    px = \n",
    "    py = \n",
    "    plt.scatter(px, py, c=colormarkers[i][0], marker=colormarkers[i][1])\n",
    "\n",
    "plt.title('Iris Dataset: Sepal width vs sepal length')\n",
    "plt.legend(set(y_iris))\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.figure('petal')\n",
    "\n",
    "for i in enumerate(set(y_iris)):\n",
    "#Esto es lo mismo para los otros dos atributos.\n",
    "    px = \n",
    "    py = \n",
    "    plt.scatter(px, py, c=colormarkers[i][0], marker=colormarkers[i][1])\n",
    "\n",
    "plt.title('Iris Dataset: petal width vs petal length')\n",
    "plt.legend(set(y_iris))\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ahora vamos a utilizar únicamente los atributos relacionados con sepal, para poder visualizar los métodos utilizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos\n",
    "Ahora que tenemos una idea del dataset, vamos a procesar los datos.\n",
    "En este caso, normalizamos los atributos.\n",
    "Lo primero que hay que hacer es separar los atributos en entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Acá tienen que dividir el conjunto en testeo y entrenamiento, les va a servir la función train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la esperanza y la varianza de los atributos, para normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "esp_width_train =\n",
    "var_width_train = \n",
    "\n",
    "esp_width_test =\n",
    "var_width_test = \n",
    "\n",
    "print ('Esperanza de sepal width (train):{:.2f} y su varianza:{:.2f}'.format(esp_width_train, var_width_train))\n",
    "print ('Esperanza de sepal width (test):{:.2f} y su varianza:{:.2f}'.format(var_width_train, var_width_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "esp_length_train =\n",
    "var_length_train = \n",
    "\n",
    "esp_length_test =\n",
    "var_length_test = \n",
    "\n",
    "print ('Esperanza de sepal length (train):{:.2f} y su varianza:{:.2f}'.format(esp_length_train, var_length_train))\n",
    "print ('Esperanza de sepal length (test):{:.2f} y su varianza:{:.2f}'.format(esp_length_test,esp_length_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizamos y estudiamos la varianza de nuevo.\n",
    "X_train = \n",
    "X_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "esp_length_train =\n",
    "var_length_train = \n",
    "\n",
    "esp_length_test =\n",
    "var_length_test = \n",
    "\n",
    "print ('Esperanza de sepal width (train):{:.2f} y su varianza:{:.2f}'.format(esp_width_train, var_width_train))\n",
    "print ('Esperanza de sepal width (test):{:.2f} y su varianza:{:.2f}'.format(var_width_train, var_width_test))\n",
    "\n",
    "\n",
    "print ('Esperanza de sepal length (train):{:.2f} y su varianza:{:.2f}'.format(esp_length_train, var_length_train))\n",
    "print ('Esperanza de sepal length (test):{:.2f} y su varianza:{:.2f}'.format(esp_length_test,esp_length_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué dio distinto en el conjunto de testeo?\n",
    "Imprimimos el conjunto de entrenamiento nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nuevamente completar xs, ys con los puntos correspondientes.\n",
    "\n",
    "colormarkers = [ ['red','s'], ['greenyellow','o'], ['blue','x']]\n",
    "plt.figure('Training Data')\n",
    "for i, val in enumerate(set(y_iris)):\n",
    "    xs = \n",
    "    ys = \n",
    "    plt.scatter(xs, ys, c=colormarkers[i][0], marker=colormarkers[i][1])\n",
    "\n",
    "plt.title('Training instances, after scaling')\n",
    "plt.legend(set(y_iris))\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un primer clasificador\n",
    "Una técnica bastante usual es convertir el problema en uno de clasificación binaria: sólo queremos distinguir flores setosas del resto (elegimos las setosas porque parecen las más fáciles).\n",
    "Para hacer esto, colapsamos las clases que no son setosa a la misma clase.\n",
    "\n",
    "Tengan cuidado de no alterar el corpus original porque lo vamos a necesitar después.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "print ('New training target classes:\\n{0}'.format(y_train_setosa))\n",
    "print ('New testing target classes:\\n{0}'.format(y_test_setosa))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comenzamos la tarea de clasificación, vamos a implementar un clasificador lineal.\n",
    "El procedimiento fit consiste en ajustar el clasificador a los valores de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model \n",
    "clf = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ahora vamos a dejar los parámetros por defecto, en las clases siguientes vamos a ver cómo elegir parámetros en cada modelo.  \n",
    "Observen que nuestro clasificador es una recta.\n",
    "Podemos dibujarla entonces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (clf.coef_,clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x_min, x_max = X_train[:, 0].min() - .5, X_train[:, 0].max() + .5\n",
    "y_min, y_max = X_train[:, 1].min() - .5, X_train[:, 1].max() + .5\n",
    "\n",
    "fig,axes = plt.subplots()\n",
    "axes.set_aspect('equal')\n",
    "axes.set_title('Setosa classification')\n",
    "axes.set_xlabel('Sepal length')\n",
    "axes.set_ylabel('Sepal width')\n",
    "axes.set_xlim(x_min, x_max)\n",
    "axes.set_ylim(y_min, y_max)\n",
    "plt.sca(axes)\n",
    "plt.scatter(X_train[:, 0][y_train == 0], X_train[:, 1][y_train == 0], c='red', marker='s')\n",
    "plt.scatter(X_train[:, 0][y_train == 1], X_train[:, 1][y_train == 1], c='black', marker='x')\n",
    "xs = # acá elegimos una cantidad arbitraria de puntos\n",
    "ys = # Para graficar la recta, utilizamos los coeficientes calculados del clasificador.\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos un predictor que nos dice si una planta es setosa o no (a la izquierda de la linea es setosa).\n",
    "Pueden probar distintos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación usando las tres clases\n",
    "\n",
    "El mismo clasificador que usamos provee etiquetado multiclase. Vamos a usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = \n",
    "print (len(clf2.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudien el resultado. ¿Cómo resolvió scikit el problema de la clasificación multiclase?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora grafiquemos el nuevo clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x_min, x_max = X_train[:, 0].min() - .5, X_train[:, 0].max() + .5\n",
    "y_min, y_max = X_train[:, 1].min() - .5, X_train[:, 1].max() + .5\n",
    "xs = \n",
    "fig, axes = plt.subplots(1,3)\n",
    "fig.set_size_inches(10,6)\n",
    "for i in range(3):\n",
    "    axes[i].set_aspect('equal')\n",
    "    axes[i].set_title('Class '+ iris.target_names[i] + ' versus the rest')\n",
    "    axes[i].set_xlabel('Sepal length')\n",
    "    axes[i].set_ylabel('Sepal width')\n",
    "    axes[i].set_xlim(x_min, x_max)\n",
    "    axes[i].set_ylim(y_min, y_max)\n",
    "    plt.sca(axes[i])\n",
    "    ys=\n",
    "    plt.plot(xs,ys)    \n",
    "    for j, val in enumerate(set(y_iris)):\n",
    "        px = X_train[:, 0][y_train == val]\n",
    "        py = X_train[:, 1][y_train == val]\n",
    "        color = colormarkers[j][0] if j==i else 'black'\n",
    "        marker = 'o' if j==i else 'x'\n",
    "        plt.scatter(px, py, c=color, marker=marker)     \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a predecir el ejemplo anterior usando el clasificador dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener estos predictores, ¿qué hacemos cuándo dos de ellos clasifican distinto a una instancia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "\n",
    "La medida más obvia es la precisión, pero, ¿por qué esto no es una buena idea?  \n",
    "Scikit-learn provee un módulo de métricas que implementa varias medidas de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = clf2.predict(X_test)\n",
    "accuracy = \n",
    "print ('Accuracy on the testing set:{:.2f}'.format(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (metrics.classification_report(y_test, y_pred, target_names=set(y_iris)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "Implementar un clasificador lineal a partir del siguiente dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "athletes = pd.read_csv('athlete_events.csv')\n",
    "athletes = athletes.dropna(subset=['Medal'], how='any')\n",
    "train, test = train_test_split(athletes, test_size=0.20)\n",
    "train.to_csv('athlete_events_train.csv')\n",
    "test.to_csv('athlete_events_test.csv')\n",
    "athletes.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
