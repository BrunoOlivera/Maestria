{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 5\n",
    "\n",
    "En esta clase vamos a entender qué son los métodos de regresion, cómo se diferencian de los de clasificación y en qué tareas aplican.\n",
    "\n",
    "## Motivación:\n",
    "\n",
    "Supongamos que MercadoLiEbre nos convoca para diseñar un servicio que, a partir de los datos históricos de sus publicaciones inmobiliarias, el sistema aprenda a tasar propiedades basado en sus características. De esta manera, cuando un usuario va a publicar su inmueble, el sistema le sugiera un precio de manera automática.\n",
    "\n",
    "### ¿Qué diferencia tiene este problema con los vistos hasta ahora?\n",
    "\n",
    "Hasta el momento vimos problemas de clasificación, donde el objetivo es **clasificar** las instancias en diferentes **categorías**.\n",
    "\n",
    "Sin embargo, para este problema en particular, lo que queremos es predecir una **cantidad**. Esto es un problema de regresión: aproximar una función real. Algunos ejemplos pueden ser: predecir el precio de una vivienda, la edad de una persona, temperaturas, velocidades, entre otras.\n",
    "\n",
    "## Error a optimizar\n",
    "\n",
    "Es importante entender la medida de error que queremos minimizar. En los problemas de clasificación, vimos algunas medidas como precision, recall o accuracy. Sin embargo, en los problemas de regresion estas medidas no aplican. Por ejemplo, la accuracy se define como la cantidad de predicciones correctas del total de predicciones hechas. Sin embargo, como estamos prediciendo un número real, es casi imposible tener predicciones exactas. Necesitamos métricas que de alguna forma penalicen las predicciones que le erraron por mucho y prefieran aquellas cuyo error fue pequeño. A continuación veremos algunas de las medidas que habitualmente se usan y están [disponibles en scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics):\n",
    "\n",
    "* Error Absoluto Medio ([*Mean Absolute Error*](https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error)): Es el error en valor absoluto, promediado en todas las instancias. En este caso, todos los errores tienen el mismo peso, ya que se promedia su valor absoluto, sin importar si es grande o chico. Una ventaja de esta métrica es que el error mantiene las unidades en que estamos trabajando. \n",
    "\n",
    "$$\\text{MAE}(y, \\hat{y}) = \\frac{1}{n_{\\text{ejemplos}}} \\sum_{i=0}^{n_{\\text{ejemplos}}-1} \\left| y_i - \\hat{y}_i \\right|.$$\n",
    "\n",
    "  Una variante sencilla de esta métrica consiste en tomar la mediana en vez del promedio, conocido como [Median Absolute Error](https://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error). Al tomar la Mediana en vez del Promedio, esta métrica es más robusta a los outliers.\n",
    "\n",
    "* Error Cuadrático Medio ([*Mean Squared Error*](https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error)): Es el promedio de los errores elevados al cuadrado. En este caso, como se promedian los cuadrados de los errores, los que tengan valores altos van a tener mayor peso que los errores pequeños. esta forma de medir el error no mantiene las unidades, aunque si tomamos la raíz cuadrada de esta métrica, usualmente conocida como RMSE por root mean squared error, sí se mantienen las unidades.\n",
    "$$\\text{MSE}(y, \\hat{y}) = \\frac{1}{n_\\text{ejemplos}} \\sum_{i=0}^{n_\\text{ejemplos} - 1} (y_i - \\hat{y}_i)^2.$$\n",
    "\n",
    "\n",
    "* Error Máximo ([*Max Error*](https://scikit-learn.org/stable/modules/model_evaluation.html#max-error)): El error máximo, calcula el peor caso de error entre el valor predicho y el real. Si las predicciones son todas perfectas, el error es 0, aunque en la práctica es improbable que suceda.\n",
    "\n",
    "$$\\text{Max Error}(y, \\hat{y}) = max(| y_i - \\hat{y}_i |)$$\n",
    "\n",
    "* R2 score, [coeficiente de determinación](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination): Mide la proporción de la variación de resultados explicada por el modelo. La mejor puntuación posible es 1.0 y puede ser negativa (porque el modelo puede ser arbitrariamente malo). Un modelo constante que siempre predice el valor esperado de y ($\\bar{y}$), sin tener en cuenta las características de entrada, obtendría una puntuación $R^2$ de 0.0.\n",
    "\n",
    "$$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$\n",
    "\n",
    "donde $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$ y $\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} \\epsilon_i^2$\n",
    "\n",
    "Usualmente los modelos de scikit que implementan regresiones, disponen de un método `score` que calcula el coeficiente $R^2$.\n",
    "\n",
    "## Ejercicio:\n",
    "Implementar las siguientes funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error_clase(y_true, y_pred):\n",
    "    # completar aqui\n",
    "    result = np.zeros_like(y_true)\n",
    "    # -----------------\n",
    "    return result\n",
    "\n",
    "def r2_score_clase(y_true, y_pred):\n",
    "    # completar aqui\n",
    "    result = np.zeros_like(y_true)\n",
    "    # -----------------\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que la implementación sea correcta. Para esto vamos a calcular el RMSE y $R^2$ con nuestra implementación y con sklearn, y verificar que ambas arrojan el mismo resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_true = np.random.uniform(size=100)\n",
    "y_pred = np.random.uniform(size=100)\n",
    "\n",
    "# Calcular ambos valores con ambas alternativas\n",
    "# completar aqui\n",
    "rmse_skit = np.zeros_like(y_true)\n",
    "rmse_clase = np.zeros_like(y_true)\n",
    "\n",
    "r2_skit = np.zeros_like(y_true)\n",
    "r2_clase = np.zeros_like(y_true)\n",
    "# -----------------\n",
    "\n",
    "# Usamos la instruccion assert para verificar que este todo ok.\n",
    "# Si no se cumple la desigualdad, arroja un error con el mensaje dado.\n",
    "# assert condicion, \"mensaje_de_error\"\n",
    "assert abs(rmse_skit - rmse_clase) <= 1e-8, '{} - {}'.format(rmse_skit, rmse_clase)\n",
    "assert abs(r2_skit - r2_clase) <= 1e-8, '{} - {}'.format(r2_skit, r2_clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston House Pricing Dataset\n",
    "Para pasar a la parte práctica, vamos a utilizar el [Boston House Pricing Dataset](http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html), que viene disponible en sckit.\n",
    "\n",
    "Comenzamos por importar las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "print(\"Los atributos son los siguientes:\\n\\t\" + \", \".join(boston.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la descripción del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos, como de costumbre, el conjunto de entrenamiento y el de test.\n",
    "Tomar el 25% del conjunto para test, y el 80% para entrenar. Los atributos para las instancias se encuentran en `boston.data` y sus correspondientes objetivos en `boston.target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# completar aqui\n",
    "X_train, X_test, y_train, y_test = np.zeros(100,10), np.zeros(100,10), np.zeros(10), np.zeros(10)\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.figure import figaspect\n",
    "\n",
    "def plot_selected_features(feature_selector, feature_names, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Graficamos los mejores atributos seleccionados según el SelectKBest.\n",
    "        X_train: matriz de atributos, (n_samples, n_features)\n",
    "        y_train: vector con los targets\n",
    "        feature_selector: instancia de SelectKBest entrenada\n",
    "        feature_names: numpy array, (n_features,) que contiene el nombre de los atributos\n",
    "    \"\"\"\n",
    "    # Obtenemos los nombres de los atributos que fueron seleccionados por el feature selector dado\n",
    "    selected_features = feature_names[feature_selector.get_support()]\n",
    "    # Obtenemos los atributos seleccionados por el feature selector dado\n",
    "    X_new = feature_selector.transform(X_train)\n",
    "    \n",
    "    sorted_idx=np.argsort(feature_selector.scores_)\n",
    "\n",
    "    # Mostramos cada atributo del dataset con su score correspondiente y si fue o no seleccionado\n",
    "    print('atributo:  score -> seleccionada\\n')\n",
    "    for support, score, name in zip(feature_selector.get_support()[sorted_idx], feature_selector.scores_[sorted_idx], feature_names[sorted_idx]):\n",
    "        print('{:>8}: {:6.2f} -> {}'.format(name, score, support))\n",
    "\n",
    "    # Creamos los k subplots\n",
    "    fig, axes = plt.subplots(1, feature_selector.k, sharey=True, sharex=False)\n",
    "\n",
    "    # Calculamos los limites del plot\n",
    "    x_min, x_max = X_new.min() - .5, X_new.max() + .5\n",
    "    y_min, y_max = y_train.min() - .5, y_train.max() + .5\n",
    "    \n",
    "    # Configuramos el tamaño para los subplots\n",
    "    w, h = figaspect((y_max-y_min)/(feature_selector.k*(x_max-x_min)))\n",
    "    fig.set_size_inches(w, h)\n",
    "\n",
    "    # Recorremos los atributos seleccionados y cada uno lo ponemos ne un eje distinto\n",
    "    for i, feature in enumerate(selected_features):\n",
    "        \n",
    "        if i == 0:\n",
    "            # Agregamos la etiqueta solamente en el primer sub plot\n",
    "            axes[i].set_ylabel('Median house value')\n",
    "        \n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_xlim(x_min, x_max)\n",
    "        axes[i].set_ylim(y_min, y_max)\n",
    "        axes[i].scatter(X_new[:,i],y_train)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, usando el selector de atributos [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) de scikit, tomar las mejores cuatro características para este conjunto de datos, y luego graficarlas utilizando la función `plot_selected_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# completar aqui\n",
    "\n",
    "# ------------------------------------------\n",
    "# verificamos que el feature_selector elije 4 atributos\n",
    "assert feature_selector.transform(X_train).shape[1] == 4\n",
    "# X_train debe contener TODOS los atributos\n",
    "plot_selected_features(feature_selector, boston.feature_names, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tareas de regresion, es muy importante normalizar los datos, por ejemplo, para evitar que los atributos con valores absolutos grandes, tengan demaciada incidencia en el resultado final. Utilizando el [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) de sckit-learn, normalizar los atributos para que tenan media -0 y desviación estándar uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# completar aqui\n",
    "\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal\n",
    "\n",
    "El primer modelo que vamos a ver es de regresión lineal. Esto es, si nuestras instancias X son de la forma $x_0, x_1, \\ldots, x_n$, podemos utilizar una aproximación lineal de la siguiente forma:\n",
    "\n",
    "$$\\hat{y}(w,x) = b + x_1 w_1 + \\ldots + x_n w_n $$\n",
    "\n",
    "Donde $b$ es simplemente el término independiente, usualmente conocido como _bias_. Muchas veces se simplifica este término en la notación, añadiendo un $x_0=1$, y renombrando $b$ con $w_0$.  Con este cambio, podemos escribirlo matricialmente de la siguiente manera:\n",
    "\n",
    "$$ \\hat{y} = Xw $$\n",
    "\n",
    "Este modelo es muy sencillo pero muchas veces es útil en la práctica. El problema que debemos resolver es encontrar los pesos que minimizan el error para el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprovechando que sckit tiene sus interfaces estandarizadas, podemos escribir una función que reciba un objeto `clf` de tipo *regression estimator* (esto es, que permite entrenar una regresión), `X_train` e `y_train` y estime el valor del error mediante validación cruzada con cinco _folds_. Reportar el promedio y la desviacion estandar del error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf, X_train, y_train):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print (\"Coeficiente de determinacion en el conjunto de entrenamiento: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    \n",
    "    # ---- COMPLETAR ----\n",
    "    mean_score = 0\n",
    "    std_score = 0\n",
    "    # -------------------\n",
    "    print (\"Coeficiente de determinacion en el conjunto de entrenamiento con 5-fold crossvalidation:\\n\" +\n",
    "           \"{:.3f} ± {:.3f}\".format(float(mean_score), float(std_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar la implementación, vamos a entrenar un objeto llamado LinearRegression del módulo sklearn.linear_model. Este regresor implementa mínimos cuadrados, esto es, encuentra los pesos $w_i$ de la siguiente forma:\n",
    "\n",
    "$$\\min_{w} || X w - y||_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression()\n",
    "train_and_evaluate(clf, X_train_scal, y_train_scal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provee un módulo entero con distintas alternativas para implementar regresiones lineales, llamado [sklearn.linear_model](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net).\n",
    "\n",
    "Al igual que los clasificadores vistos hasta el momento, implementan los métodos `fit`, `predict` y `score`, pero además, en el caso de los modelo lineales, tienen dos atributos muy útiles: `coef_` para obtener el vector $w_1 w_n$, y `intercept_` para obtener el término independiente $w_0$.\n",
    "\n",
    "Estos valores son muy importantes a la hora de interpretar el modelo para entender qué está aprendiendo nuestro modelo, y a qué le está dando relevancia.\n",
    "\n",
    "A continuación, vamos a escribir una función genérica que, dado un regresor lineal, nos muestre sus pesos, ordenados según su importancia.\n",
    "Sugerencia: utilizar la función `plt.bar` de [matplotlib](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.bar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mostrar_pesos(clf, feature_names):\n",
    "    # ---- COMPLETAR ----\n",
    "    pass\n",
    "    # -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = boston.feature_names[feature_selector.get_support()]\n",
    "mostrar_pesos(clf, selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un regresor entrenado, utilizando sus atributos `coef_` para obtener el vector $w_1 w_n$, y `intercept_` para el $w_0$, verificar que todos los estimados por el clasificador son exactamente iguales a calculados manualmente a partir de dichos coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def regresion_manual(clf, X):\n",
    "    # ---- COMPLETAR ----\n",
    "    y_pred = np.zeros(len(X))\n",
    "    # --------------------\n",
    "    return y_pred\n",
    "\n",
    "# Verificamos que ambas estimaciones dan lo mismo\n",
    "y_pred_clase = regresion_manual(clf, X_train_scal)\n",
    "y_pred_scikit = clf.predict(X_train_scal)\n",
    "\n",
    "assert np.sum(np.abs(y_pred_clase - y_pred_scikit)) <= 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar que las funciones desarrolladas (`train_and_evaluate`, `mostrar_pesos`, y `regresion_manual`) tambien funcionan correctamente para los modelos lineales [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) y [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "# ---- COMPLETAR ----\n",
    "pass\n",
    "# --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión polinómica\n",
    "\n",
    "Con modelos lineales, únicamente se pueden aprender relaciones lineales entre los datos. Sin ambargo, se pueden combinar los atributos entre sí. Scikit-learn implementa la clase [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html), que genera automáticamente combinaciones polinómicas de los atributos. Por ejemplo, a partir de los atributos $ x_1, x_2$, se puede obtener los polinomios de hasta segundo grado, que son los siguientes:\n",
    "\n",
    "$$1, x_1, x_2, x_1^2, x_1x_2, x_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, entrenar un clasificador lineal incluyendo atributos polinómicos, de orden 2 o menor, tomando los mejores 4 de todas las combinaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# ---- COMPLETAR ----\n",
    "pass\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_selected_features(feature_selector, np.array(poli.get_feature_names()), X_train_poli, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vecinos más cercanos\n",
    "\n",
    "Este método es muy sencillo, consiste en estimar el valor de la función en cada punto, a partir de una aproximaciòn local a dicho punto. En su versión más sencilla, [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) toma los $k$ puntos más cercanos, y los promedia. \n",
    "\n",
    "Una variante sencilla, consiste en tomar todos los puntos que estén a menos de $r$, y promediar su valor. Esto lo implementa [RadiusNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier).\n",
    "\n",
    "Entrenar un regresor [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html). Encontrar un buen valor de $k$ y verificar si ponderar el promedio con distancias (`weights='distance'`) es mejor que no hacerlo (`weights='uniform'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- COMPLETAR ----\n",
    "pass\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerar que hasta el momento, para entrenar el regresor pasamos por varios pasos:\n",
    " * 1) Elegimos los mejores k atributos\n",
    " * 2) Normalizamos (forzamos media 0, desviación estándar 1)\n",
    " * 3) Agregamos todos los atributos polinómicos y nos quedamos con algunos (opcional)\n",
    " * 4) Entrenamos el regresor sobre los atributos restantes\n",
    " \n",
    "Para poner todos los pasos juntos, se puede definir un [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) de scikit: esto simplemente es un objeto donde se le indican uno a uno los pasos a seguir.\n",
    "\n",
    "Para la mejor configuración encontrada durante toda la clase, definir el pipeline correspondiente, evaluar los resultados en el conjunto de test. Reportar el RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# ---- COMPLETAR ----\n",
    "pass\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**opcional**: aplicando las estrategias [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) o [RandomizedSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) se puede seleccionar hiperparámetros para todo el pipeline definido.\n",
    "\n",
    "Encontrar una buena configuración de parámetros para el pipeline definido en la parte anterior. Evaluarlo en el conjunto de test y compararlo con los esultados encontrados manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "# ---- COMPLETAR ----\n",
    "pass\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, utilizando las herramientas vistas en clase, implementar un regresor que ajuste correctamente los datos del [diabetes_dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- COMPLETAR ----\n",
    "pass\n",
    "# -------------------"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
